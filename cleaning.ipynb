{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47160fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processed_Sentence_1</th>\n",
       "      <th>Processed_Sentence_2</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gk muluk muluk, 100,000 lot saham BBCA aja</td>\n",
       "      <td>Gk muluk muluk, 100,000 lot saham BBCA aja</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCA Expoversary 2024 menawarkan promo suku bun...</td>\n",
       "      <td>BCA Expoversary 2024 menawarkan promo suku bun...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saham bca nya menyusul ya ðŸ™‚</td>\n",
       "      <td>saham bca nya menyusul ya ðŸ™‚</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PT Bank BCA Syariah (BCA Syariah) turut memeri...</td>\n",
       "      <td>PT Bank BCA Syariah (BCA Syariah) turut memeri...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Begitu byk saham kamu memilih saham itu kalau ...</td>\n",
       "      <td>Begitu byk saham kamu memilih saham itu kalau ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Processed_Sentence_1  \\\n",
       "0         Gk muluk muluk, 100,000 lot saham BBCA aja   \n",
       "1  BCA Expoversary 2024 menawarkan promo suku bun...   \n",
       "2                        saham bca nya menyusul ya ðŸ™‚   \n",
       "3  PT Bank BCA Syariah (BCA Syariah) turut memeri...   \n",
       "4  Begitu byk saham kamu memilih saham itu kalau ...   \n",
       "\n",
       "                                Processed_Sentence_2 Sentiment  \n",
       "0         Gk muluk muluk, 100,000 lot saham BBCA aja  Positive  \n",
       "1  BCA Expoversary 2024 menawarkan promo suku bun...   Neutral  \n",
       "2                        saham bca nya menyusul ya ðŸ™‚  Positive  \n",
       "3  PT Bank BCA Syariah (BCA Syariah) turut memeri...   Neutral  \n",
       "4  Begitu byk saham kamu memilih saham itu kalau ...  Positive  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"indo_raw_TEST_emoji.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55bc559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processed_Sentence_1</th>\n",
       "      <th>Processed_Sentence_2</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Processed_Sentence_1, Processed_Sentence_2, Sentiment]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_rows = df[df[\"Processed_Sentence_1\"] != df[\"Processed_Sentence_2\"]]\n",
    "\n",
    "diff_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1423de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "main_df = pd.read_csv(\"IDSMSA.csv\")\n",
    "\n",
    "slang_df = pd.read_csv(\"kamus_kata_baku.csv\")\n",
    "slang_dict = dict(zip(slang_df['kata_tidak_baku'], slang_df['kata_baku']))\n",
    "\n",
    "emoji_df_indo = pd.read_csv(\"kamus_emoji_indo.csv\")\n",
    "emoji_dict_indo = dict(zip(emoji_df_indo['emoji'], emoji_df_indo['kata_emoji']))\n",
    "emoji_list_indo = emoji_df_indo['emoji'].tolist()\n",
    "\n",
    "emoji_df_inggris = pd.read_csv(\"kamus_emoji_inggris.csv\")\n",
    "emoji_dict_inggris = dict(zip(emoji_df_inggris['emoji'], emoji_df_inggris['kata_emoji']))\n",
    "\n",
    "emoji_list_combined = list(set(emoji_list_indo + emoji_df_inggris['emoji'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c4c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_reduplication(text):\n",
    "    return re.sub(r'(\\w+)[\\u00B2](\\w*)', r'\\1-\\1\\2', str(text))\n",
    "\n",
    "def separate_punctuation(text):\n",
    "    return re.sub(r'([.,!?;:])', r' \\1 ', str(text))\n",
    "\n",
    "def remove_placeholders(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    text = re.sub(r'\\[USERNAME\\]|\\[URL\\]|\\[HASHTAG\\]', '', text, flags=re.IGNORECASE)\n",
    "    return text.strip()\n",
    "\n",
    "def normalize_slang(text, slang_dict):\n",
    "    words = text.split()\n",
    "    normalized_words = [slang_dict.get(word.lower(), word) for word in words]\n",
    "    return ' '.join(normalized_words)\n",
    "\n",
    "def clean_final_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def translate_emojis(text, emoji_dict):\n",
    "    text = str(text)\n",
    "    for emoji, word in emoji_dict.items():\n",
    "        text = text.replace(emoji, f' {word} ') # Add spaces for separation\n",
    "    return text\n",
    "\n",
    "def remove_all_emojis(text, emoji_list):\n",
    "    text = str(text)\n",
    "    for emoji in emoji_list:\n",
    "        text = text.replace(emoji, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c17369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cleaned_indo_pipeline(text, slang_dict, emoji_dict, emoji_list, emoji_option='keep'):\n",
    "    text = handle_reduplication(text)\n",
    "    \n",
    "    if emoji_option == 'translate':\n",
    "        text = translate_emojis(text, emoji_dict)\n",
    "    elif emoji_option == 'remove':\n",
    "        text = remove_all_emojis(text, emoji_list)\n",
    "        \n",
    "    text = remove_placeholders(text)\n",
    "    \n",
    "    text = separate_punctuation(text)\n",
    "    \n",
    "    text = normalize_slang(text, slang_dict)\n",
    "    \n",
    "    text = clean_final_text(text)\n",
    "    return text\n",
    "\n",
    "def create_cleaned_eng_pipeline(text, emoji_dict, emoji_list, emoji_option='keep'):\n",
    "    if emoji_option == 'translate':\n",
    "        text = translate_emojis(text, emoji_dict)\n",
    "    elif emoji_option == 'remove':\n",
    "        text = remove_all_emojis(text, emoji_list)\n",
    "        \n",
    "    text = remove_placeholders(text)\n",
    "    text = clean_final_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1da53dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"other output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\nStarting dataset generation... Output will be saved in '{output_dir}/'\")\n",
    "\n",
    "# --- INDONESIAN DATASETS ---\n",
    "# 1. Cleaned (with emoji)\n",
    "df1 = main_df.copy()\n",
    "df1['Processed_Sentence'] = df1['Sentence'].apply(lambda t: create_cleaned_indo_pipeline(t, slang_dict, emoji_dict_indo, emoji_list_combined, emoji_option='keep'))\n",
    "df1_final = df1[['Sentence', 'Processed_Sentence', 'Sentiment']].rename(columns={'Sentence': 'Original_Sentence'})\n",
    "df1_final.to_csv(os.path.join(output_dir, \"indo_cleaned_with_emoji.csv\"), index=False)\n",
    "print(\"1. Generated: indo_cleaned_with_emoji.csv\")\n",
    "\n",
    "# 2. Cleaned (no emoji)\n",
    "df2 = main_df.copy()\n",
    "df2['Processed_Sentence'] = df2['Sentence'].apply(lambda t: create_cleaned_indo_pipeline(t, slang_dict, emoji_dict_indo, emoji_list_combined, emoji_option='remove'))\n",
    "df2_final = df2[['Sentence', 'Processed_Sentence', 'Sentiment']].rename(columns={'Sentence': 'Original_Sentence'})\n",
    "df2_final.to_csv(os.path.join(output_dir, \"indo_cleaned_no_emoji.csv\"), index=False)\n",
    "print(\"2. Generated: indo_cleaned_no_emoji.csv\")\n",
    "\n",
    "# 3. Cleaned (kata_emoji)\n",
    "df3 = main_df.copy()\n",
    "df3['Processed_Sentence'] = df3['Sentence'].apply(lambda t: create_cleaned_indo_pipeline(t, slang_dict, emoji_dict_indo, emoji_list_combined, emoji_option='translate'))\n",
    "df3_final = df3[['Sentence', 'Processed_Sentence', 'Sentiment']].rename(columns={'Sentence': 'Original_Sentence'})\n",
    "df3_final.to_csv(os.path.join(output_dir, \"indo_cleaned_kata_emoji.csv\"), index=False)\n",
    "print(\"3. Generated: indo_cleaned_kata_emoji.csv\")\n",
    "\n",
    "# 4. Raw (with emoji)\n",
    "df4 = main_df.copy()\n",
    "df4['Processed_Sentence'] = df4['Sentence'].apply(remove_placeholders)\n",
    "df4_final = df4[['Sentence', 'Processed_Sentence', 'Sentiment']].rename(columns={'Sentence': 'Original_Sentence'})\n",
    "df4_final.to_csv(os.path.join(output_dir, \"indo_raw_with_emoji.csv\"), index=False)\n",
    "print(\"4. Generated: indo_raw_with_emoji.csv\")\n",
    "\n",
    "# 5. Raw (no emoji)\n",
    "df5 = main_df.copy()\n",
    "df5['Processed_Sentence'] = df5['Sentence'].apply(remove_placeholders)\n",
    "df5['Processed_Sentence'] = df5['Processed_Sentence'].apply(lambda t: remove_all_emojis(t, emoji_list_combined))\n",
    "df5_final = df5[['Sentence', 'Processed_Sentence', 'Sentiment']].rename(columns={'Sentence': 'Original_Sentence'})\n",
    "df5_final.to_csv(os.path.join(output_dir, \"indo_raw_no_emoji.csv\"), index=False)\n",
    "print(\"5. Generated: indo_raw_no_emoji.csv\")\n",
    "\n",
    "# 6. Raw (kata_emoji)\n",
    "df6 = main_df.copy()\n",
    "df6['Processed_Sentence'] = df6['Sentence'].apply(remove_placeholders)\n",
    "df6['Processed_Sentence'] = df6['Processed_Sentence'].apply(lambda t: translate_emojis(t, emoji_dict_indo))\n",
    "df6_final = df6[['Sentence', 'Processed_Sentence', 'Sentiment']].rename(columns={'Sentence': 'Original_Sentence'})\n",
    "df6_final.to_csv(os.path.join(output_dir, \"indo_raw_kata_emoji.csv\"), index=False)\n",
    "print(\"6. Generated: indo_raw_kata_emoji.csv\")\n",
    "\n",
    "# --- ENGLISH DATASETS ---\n",
    "# 7. Cleaned English (with emoji)\n",
    "df7 = main_df.copy()\n",
    "df7['Processed_Sentence'] = df7['English Translation'].apply(lambda t: create_cleaned_eng_pipeline(t, emoji_dict_inggris, emoji_list_combined, emoji_option='keep'))\n",
    "df7_final = df7[['English Translation', 'Processed_Sentence', 'Sentiment']].rename(columns={'English Translation': 'Original_Sentence'})\n",
    "df7_final.to_csv(os.path.join(output_dir, \"eng_cleaned_with_emoji.csv\"), index=False)\n",
    "print(\"7. Generated: eng_cleaned_with_emoji.csv\")\n",
    "\n",
    "# 8. Cleaned English (no emoji)\n",
    "df8 = main_df.copy()\n",
    "df8['Processed_Sentence'] = df8['English Translation'].apply(lambda t: create_cleaned_eng_pipeline(t, emoji_dict_inggris, emoji_list_combined, emoji_option='remove'))\n",
    "df8_final = df8[['English Translation', 'Processed_Sentence', 'Sentiment']].rename(columns={'English Translation': 'Original_Sentence'})\n",
    "df8_final.to_csv(os.path.join(output_dir, \"eng_cleaned_no_emoji.csv\"), index=False)\n",
    "print(\"8. Generated: eng_cleaned_no_emoji.csv\")\n",
    "\n",
    "# 9. Cleaned English (kata_emoji)\n",
    "df9 = main_df.copy()\n",
    "df9['Processed_Sentence'] = df9['English Translation'].apply(lambda t: create_cleaned_eng_pipeline(t, emoji_dict_inggris, emoji_list_combined, emoji_option='translate'))\n",
    "df9_final = df9[['English Translation', 'Processed_Sentence', 'Sentiment']].rename(columns={'English Translation': 'Original_Sentence'})\n",
    "df9_final.to_csv(os.path.join(output_dir, \"eng_cleaned_kata_emoji.csv\"), index=False)\n",
    "print(\"9. Generated: eng_cleaned_kata_emoji.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cb9533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Sentence</th>\n",
       "      <th>Processed_Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>Apakah memang sudah tidak tertolong ðŸ¤” shm! $UNVR ??? [URL]</td>\n",
       "      <td>Apakah memang sudah tidak tertolong  shm! $UNVR ???</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Original_Sentence  \\\n",
       "457  Apakah memang sudah tidak tertolong ðŸ¤” shm! $UNVR ??? [URL]   \n",
       "\n",
       "                                      Processed_Sentence Sentiment  \n",
       "457  Apakah memang sudah tidak tertolong  shm! $UNVR ???  Negative  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.read_csv(\"Data Output/indo_raw_no_emoji.csv\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "p.iloc[[457]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
